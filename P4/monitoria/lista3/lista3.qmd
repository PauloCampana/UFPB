---
format: pdf
title: Probabilidade II
subtitle: Lista 3
---

::: hidden
\pagestyle{empty}
\thispagestyle{empty}
\def \p #1{{ \text{P} \kern-2pt \left( #1 \right) }}
\def \E #1{{ \text{E} \left[ #1 \right] }}
\def \Var #1{{ \text{Var} \left[ #1 \right] }}
:::

###### 1. Suponha que $X$ tenha a seguinte densidade: $f(x) = \lambda e^{-\lambda (x-a)}$, $x \geqslant a$.
a. Determine a função geradora de momentos de $X$.
b. Empregando a função geradora de momentos, calcule $\E{X}$ e $\Var{X}$.

::: {layout-ncol=2}
\begin{align*}
    M_X(t)
    &= \int \limits_a^\infty e^{tx} \lambda e^{-\lambda (x-a)} dx \\
    &= \lambda e^{\lambda a} \int \limits_a^\infty e^{-x (\lambda - t)} dx \\
    &= \lambda e^{\lambda a} \left( \dfrac{-e^{-x (\lambda - t)}}{\lambda - t} \right) \Bigr|_a^\infty \\
    &= \lambda e^{\lambda a} \dfrac{e^{-\lambda a} e^{at}}{\lambda - t} \\
    &= \dfrac{\lambda e^{at}}{\lambda - t}
\end{align*}

\begin{align*}
    \E{X} 
    &= M_X'(t) \Big|_0 \\
    &= \dfrac{(\lambda - t)(a \lambda e^{at}) - (\lambda e^{at})(-1)}{(\lambda - t)^2} \Big|_0 \\
    &= \dfrac{(\lambda)(a \lambda) - (\lambda)(-1)}{(\lambda)^2} \\
    &= \dfrac{a \lambda^2 + \lambda}{\lambda^2} \\
    &= a + \dfrac{1}{\lambda} 
\end{align*}
:::

::: {layout-ncol=2}
\begin{align*}
    \E{X^2} 
    &= M_X''(t) \Big|_0 \\
    &= \dfrac{a^2 \lambda e^{at}}{\lambda - t} + 
    \dfrac{2a \lambda e^{at}}{(\lambda - t)^2} + 
    \dfrac{2 \lambda e^{at}}{(\lambda - t)^3} \Big|_0 \\
    &= a^2 + \dfrac{2a}{\lambda} + \dfrac{2}{\lambda^2}
\end{align*}

\begin{align*}
    \Var{X} 
    &= \E{X^2} - \E{X}^2 \\
    &= a^2 + \dfrac{2a}{\lambda} + \dfrac{2}{\lambda^2} - 
    \left( a + \dfrac{1}{\lambda} \right)^2 \\
    &= a^2 + \dfrac{2a}{\lambda} + \dfrac{2}{\lambda^2} - 
    a^2 - \dfrac{2a}{\lambda} - \dfrac{1}{\lambda^2} \\
    &= \dfrac{1}{\lambda^2}
\end{align*}
:::
 
{{< pagebreak >}}
 
###### 2. Se a variável aleatória $X$ tiver uma função geradora de momentos dada por $M_X(t) = 3 / (3 - t)$, qual será o desvio padrão de $X$?

Sabemos que a f.g.m. de uma V.A. exponencial é dada por $\lambda / (\lambda - t)$, comparando com $3 / (3 - t)$, vemos que $X$ é uma V.A. exponencial de parâmetro 3.

Sua variância é dada por $1/9$ então o desvio padrão é $1/3$.

---

###### 4. Seja $(X,Y)$ um vetor aleatório discreto bidimensional com função de probabilidade conjunta dada pela tabela dupla entrada a seguir.

a) Verifique que trata-se de uma legítima função de probabilidade conjunta e obtenha as funções de probabilidade marginais de $X$ e $Y$.
b) Determine se $X$ e $Y$ são independentes.

Completando a tabela com os totais das linhas e colunas obtemos as probabilidades marginais

::: {layout-ncol=2}
|X \textbackslash Y|  0   |  1   |  2   |
|:-----------------|:----:|:----:|:----:|
|0                 | 0.20 | 0.15 | 0.15 |
|1                 | 0.16 | 0.12 | 0.12 |
|2                 | 0.04 | 0.03 | 0.03 |

|X \textbackslash Y|  0   |  1   |  2   | P(X = x) |
|:-----------------|:----:|:----:|:----:|:--------:|
|0                 | 0.20 | 0.15 | 0.15 |   0.5    |
|1                 | 0.16 | 0.12 | 0.12 |   0.4    |
|2                 | 0.04 | 0.03 | 0.03 |   0.1    |
|P(Y = y)          | 0.40 | 0.30 | 0.30 |   1.0    |
:::

Tanto a probabilidade conjunta quanto as marginais são positivas e suas somas são 1, portanto é uma função de probabilidade conjunta legítima.

$X$ e $Y$ também são independentes, pois para qualquer $(x,y)$, $P_{X,Y}(x,y) = P_X(x) P_Y(y)$. 

\begin{align*}
    P_{X,Y}(0,0) = 0.20 = (0.50) (0.40) = P_X(0) \cdot P_Y(0) \\
    P_{X,Y}(0,1) = 0.15 = (0.50) (0.30) = P_X(0) \cdot P_Y(1) \\
    P_{X,Y}(0,2) = 0.15 = (0.50) (0.30) = P_X(0) \cdot P_Y(2) \\
    P_{X,Y}(1,0) = 0.16 = (0.40) (0.40) = P_X(1) \cdot P_Y(0) \\
    P_{X,Y}(1,1) = 0.12 = (0.40) (0.30) = P_X(1) \cdot P_Y(1) \\
    P_{X,Y}(1,2) = 0.12 = (0.40) (0.30) = P_X(1) \cdot P_Y(2) \\
    P_{X,Y}(2,0) = 0.04 = (0.10) (0.40) = P_X(2) \cdot P_Y(0) \\
    P_{X,Y}(2,1) = 0.03 = (0.10) (0.30) = P_X(2) \cdot P_Y(1) \\
    P_{X,Y}(2,2) = 0.03 = (0.10) (0.30) = P_X(2) \cdot P_Y(2)
\end{align*}

###### 5. Sejam $X$ e $Y$ duas variáveis aleatórias discretas e $g$ e $h$ duas funções quaisquer. Mostre que se $X$ e $Y$ são independentes, então $\E{g(X)h(Y)} = \E{g(X)}\E{h(Y)}$.

Usando a definição de esperança para V.A.s discretas

\begin{align*}
    \E{g(X)h(Y)} 
    &= \sum_{i \in S_X} \sum_{j \in S_Y} g(X) h(Y) \p{X = i, Y = j} \\
    &= \sum_{i \in S_X} \sum_{j \in S_Y} g(X) h(Y) \p{X = i} \p{Y = j} \\
    &= \sum_{i \in S_X} g(X) \p{X = i} \sum_{j \in S_Y} h(Y) \p{Y = j} \\
    &= \left( \sum_{j \in S_Y} h(Y) \p{Y = j} \right) \left( \sum_{i \in S_X} g(X) \p{X = i} \right) \\
    &= \E{h(Y)} \E{g(X)}
\end{align*}

---

###### 6. Dizemos que uma variável aleatória $X$ tem distribuição qui-quadrado com $\kappa$ graus de liberdade se sua densidade é dada por

$$
f(x) = \dfrac{x^{\kappa/2 - 1} e^{-x/2}}{2^{\kappa/2} \Gamma(\kappa/2)}, \quad x \geqslant 0.
$$

Sejam $X_1$ e $X_2$ variáveis aleatórias independentes com distribuição qui-quadrado com $\kappa_1$ e $\kappa_2$ graus de liberdade, respectivamente.

a) Mostre que a função geradora de momentos de $Z = X_1 + X_2$ é $\psi_Z(t) = (1 - 2t)^{-(\kappa_1 + \kappa_2)/2}$.
b) Mostre que $Z$ tem distribuição qui-quadrado com $\kappa_1 + \kappa_2$ graus de liberdade.

Utilizando o resultado da questão 5. temos que:

\begin{align*}
    \E{g(X)h(Y)}      &= \E{g(X)}\E{h(Y)}     \\
    \E{e^{tX}e^{tX}}  &= \E{e^{tX}}\E{e^{tY}} \\
    \E{e^{t (X + Y)}} &= \E{e^{tX}}\E{e^{tY}} \\
    M_{X + Y}(t)      &= M_X(t)M_Y(t)         \\
\end{align*}

Então para encontrar a f.g.m. de $Z$, basta encontrar a f.g.m. de $X_1$ e $X_2$ e multiplicar.

\begin{align*}
    M_{X}(t) &\implies
    \int \limits_0^\infty e^{tx} \dfrac{x^{\kappa/2 - 1} e^{-x/2}}{2^{\kappa/2} \Gamma(\kappa/2)} dx \\
    \text{juntado as exponenciais} &\implies
    \int \limits_0^\infty \dfrac{x^{\kappa/2 - 1} e^{-x (1 - 2t) / 2}}{2^{\kappa/2} \Gamma(\kappa/2)} dx \\
    \text{introduzindo o termo} \; (1-2t)^{\kappa/2} &\implies
    \dfrac{1}{(1-2t)^{\kappa/2}} \int \limits_0^\infty (1-2t)^{\kappa/2} \dfrac{x^{\kappa/2 - 1} e^{-x (1 - 2t) / 2}}{2^{\kappa/2} \Gamma(\kappa/2)} dx \\
    \text{juntando} \; x \; \text{e} \; (1-2t) \; \text{no mesmo expoente} &\implies 
    \dfrac{1}{(1-2t)^{\kappa/2}} \int \limits_0^\infty [x (1-2t)]^{\kappa/2 - 1} \dfrac{e^{-x (1 - 2t) / 2}}{2^{\kappa/2} \Gamma(\kappa/2)} dx \\
    \text{a integral é uma densidade, igual a 1} &\implies
    \dfrac{1}{(1-2t)^{\kappa/2}} \\
    &\implies (1-2t)^{-\kappa/2}
\end{align*}

\begin{align*}
    \psi_Z(t) 
    &= \psi_{X_1}(t) \psi_{X_2}(t) \\
    &= (1-2t)^{-\kappa_1/2} (1-2t)^{-\kappa_2/2} \\
    &= (1-2t)^{-(\kappa_1 + \kappa_2)/2}
\end{align*}

Comparando com a f.g.m. de uma qui-quadrado de $\kappa$ graus de liberdade, $(1-2t)^{-\kappa/2}$, vemos que $Z$ tem distribuição qui-quadrado com $\kappa_1 + \kappa_2$ graus de liberdade.

---

###### 7. A distribuição de probabilidade conjunta de $(X,Y)$ é dada por $p(1,1) = 1/8$, $p(1,2) = 1/4$, $p(2,1) = 1/8$ e $p(2, 2) = 1/2$. $X$ e $Y$ são variáveis aleatórias independentes? Calcule

Completando o quadro de probabilidades, vemos que $X$ e $Y$ não são independentes, por exemplo, $\p{X = 1, Y = 1} \neq \p{X = 1}\p{Y = 1}$ pois $1/8 \neq 3/8 \cdot 1/4$.

|X \textbackslash Y|  1  |  2  | P(X = x) |
|:-----------------|:---:|:---:|:--------:|
|1                 | 1/8 | 1/4 |   3/8    |
|2                 | 1/8 | 1/2 |   5/8    |
|P(Y = y)          | 1/4 | 3/4 |    1     |

a) $\p{XY \leqslant 3}$

$$
\p{XY \leqslant 3} = 1 - \p{XY > 3} = 1 - \p{X = 2, Y = 2} = 1 - 1/2 = 1/2
$$

b) $\p{X + Y > 2}$

$$
\p{X + Y > 2} = 1 - \p{X + Y \leqslant 2} = 1 - \p{X + Y = 2} = 1 - 1/8 = 7/8
$$

c) $\p{X/Y = 1}$

$$
\p{X/Y = 1} = \p{X = Y} = 
$$
$$
\p{X = 1, Y = 1} + \p{X = 2, Y = 2} = 1/8 + 1/2 = 5/8
$$

d) $\p{X - Y < 1}$

$$
\p{X - Y < 1} = 1 - \p{X - Y \geqslant 1} = 1 - \p{X - Y = 1} = 
$$
$$
1 - \p{X = 2, Y = 1} = 1 - 1/8 = 7/8
$$

{{< pagebreak >}}

###### 8. Sejam $X_1, \cdots, X_n$ variáveis aleatórias independentes, cujas funções de distribuição são $F_1, \cdots, F_n$, respectivamente. Mostre que as expressões da função de distribuição de $Y_{1} = \min(X_1, \cdots, X_n)$ e $Y_{n} = \max(X_1, \cdots, X_n)$ são dadas, respectivamente, por: 

::: {layout-ncol=2}
$$
F_{Y_{1}}(z) = 1 - \prod_{i = 1}^n [1 - F_i(z)]
$$

$$
F_{Y_{n}}(\omega) = \prod_{i = 1}^n F_i(\omega)
$$
:::

O máximo de um vetor aleatório é menor ou igual a um valor dado $\omega$ se e somente se, cada um dos $X_i$ for menor ou igual a $\omega$, ou seja:

\begin{align*}
    F_{Y_n}(\omega) 
    &= \p{X_{\max} \leqslant \omega} \\
    &= \p{X_1 \leqslant \omega, \cdots, X_n \leqslant \omega} \\
    &= \p{X_1 \leqslant \omega} \cdots \p{X_n \leqslant \omega} \\
    &= F_1(\omega) \cdots F_n(\omega) \\
    &= \prod_{i = 1}^n F_i(\omega)
\end{align*}

O mínimo de um vetor aleatório é maior a um valor dado $z$ se e somente se, cada um dos $X_i$ for maior a $\omega$, ou seja:

\begin{align*}
    F_{Y_1}(z)
    &= \p{X_{\min} \leqslant z} \\
    &= 1 - \p{X_{\min} > z} \\
    &= 1 - \p{X_1 > z, \cdots, X_n > z} \\
    &= 1 - \p{X_1 > z} \cdots \p{X_n > z} \\
    &= 1 - [1 - \p{X_1 \leqslant z}] \cdots [1 - \p{X_n \leqslant z}] \\
    &= 1 - [1 - F_1(z)] \cdots [1 - F_n(z)] \\
    &= 1 - \prod_{i = 1}^n [1 - F_i(z)] \\
\end{align*}

{{< pagebreak >}}

###### 9. Sejam $X_1, \cdots, X_n$ independentes, tais que $X_i \sim \text{Unif}(0, \theta)$, $\theta > 0$. Obtenha a função de distribuição acumulada de $Y = \max(X_1, \cdots, X_n)$ e $W = \min(X_1, \cdots, X_n)$.

Sabemos da função de distribuição de $X_i$ como

$$
F_{X_i}(x) = \begin{cases}
    0,    \quad \; \text{se} \; \quad \; \; \;   x < 0      \\
    x / \theta, \; \text{se} \;      0 \leqslant x < \theta \\
    1,    \quad \; \text{se} \; \theta \leqslant x
\end{cases}
$$

Utilizando o resultado anterior, para $0 \leqslant y,w < \theta$:

::: {layout-ncol=2}
\begin{align*}
    F_Y(y) 
    &= 1 - \prod_{i = 1}^n [1 - F_i(y)] \\
    &= 1 - \prod_{i = 1}^n [1 - x / \theta] \\
    &= 1 - [1 - x / \theta]^n 
\end{align*}

\begin{align*}
    F_W(w) 
    &= \prod_{i = 1}^n F_i(w) \\
    &= \prod_{i = 1}^n x / \theta \\
    &= [x / \theta]^n 
\end{align*}
:::

::: {layout-ncol=2}
$$
F_Y(y) = \begin{cases}
    0,    \qquad\qquad\quad \; \; \;  \text{se} \; \quad \; \; \;  y < 0   \\
    1 - [1 - y / \theta]^n ,      \; \text{se} \;      0 \leqslant y < \theta \\
    1,    \qquad\qquad\quad \; \; \; \text{se} \; \theta \leqslant y
\end{cases}
$$

$$
F_W(w) = \begin{cases}
    0,    \qquad   \ \; \text{se} \; \quad \; \; \;   w < 0   \\
    [w / \theta]^n , \; \text{se} \;      0 \leqslant w < \theta \\
    1,    \qquad   \ \; \text{se} \; \theta \leqslant w
\end{cases}
$$
:::

{{< pagebreak >}}

###### 10. Seja $(X,Y)$ um vetor aleatório discreto bidimensional com funçãao de probabilidade conjunta dada pela tabela dupla entrada a seguir. Determine a função de probabilidade de $Z = X + Y$.

|X \textbackslash Y|   1|   2|   3|
|:----------------:|:--:|:--:|:--:|
|1                 | 0.1| 0.1| 0.0|
|2                 | 0.1| 0.2| 0.3|
|3                 | 0.1| 0.1| 0.0|
\begin{align*}
    \p{X+Y = 2} &= \p{X=1,Y=1} = 0.1 \\
    \p{X+Y = 3} &= \p{X=2,Y=1} + \p{X=1,Y=2} = 0.1 + 0.1 = 0.2 \\
    \p{X+Y = 4} &= \p{X=3,Y=1} + \p{X=2,Y=2} + \p{X=1,Y=3} = 0.1 + 0.2 + 0.0 = 0.3 \\
    \p{X+Y = 5} &= \p{X=3,Y=2} + \p{X=2,Y=3} = 0.1 + 0.3 = 0.4 \\
    \p{X+Y = 6} &= \p{X=3,Y=3} = 0.0
\end{align*}

|z       |   2|   3|   4|   5|  6|
|:------:|---:|---:|---:|---:|--:|
|P(Z = z)| 0.1| 0.2| 0.3| 0.4|  0|

---

###### 11. Uma urna contém três bolas numeradas 1, 2 e 3. Duas bolas são tiradas sucessivamente da urna, ao acaso e sem reposição. Seja $X$ o número da primeira bola tirada e $Y$ o número da segunda.

a) Descreva a distribuição conjunta de $X$ e $Y$.
b) Calcule $\p{X < Y}$.

Como as bolas são tiradas da urna sem reposição, $\p{X=Y} = 0$.

::: {layout="[30,70]"}
|X \textbackslash Y|1   |2   |3   |
|:----------------:|:--:|:--:|:--:|
|1                 |0   |1/6 |1/6 |
|2                 |1/6 |0   |1/6 |
|3                 |1/6 |1/6 |0   |

\begin{align*}
    \p{X < Y}
    &= \p{X=1,Y=2} + \p{X=1,Y=3} + \p{X=2,Y=3} \\
    &= 1/6 + 1/6 + 1/6 \\
    &= 1/2
\end{align*}
:::

{{< pagebreak >}}

###### 12. Determine se cada uma das seguintes afirmações é verdadeira ou falsa.

a) Se $X_1, \cdots, X_5$ são variáveis aleatórias independentes, tais que $X_i \sim \text{Poisson}(i)$, $i = 1, \cdots, 5$, então $X_1 + \cdots + X_5 \sim \text{Poisson}(15)$.

Verdadeiro, usando o fato de que $M_{X + Y}(t) = M_X(t)M_Y(t)$ vista na questão 6. e que a f.g.m. de uma $\text{Poisson}(\lambda)$ é dada por $e^{\lambda(e^t-1)}$, podemos ver que soma de duas V.A.s de distribuição Poisson é também Poisson com a soma dos parâmetros $\lambda$ de cada um.
\begin{align*}
    M_{X + Y}(t) 
    = \ &M_X(t)M_Y(t) \\
    = \ &e^{\lambda_1(e^t-1)} e^{\lambda_2(e^t-1)} \\
    = \ &e^{(\lambda_1+\lambda_2)(e^t-1)} \\
    \implies &X+Y \sim \text{Poisson}(\lambda_1 + \lambda_2)
\end{align*}

Por indução, isso pode ser generalizado para soma de qualquer número de V.A.s.

b) Se X é uma variável aleatória com função geradora de momentos $\psi_X(t) = e^{2.5 e^t - 2.5}$, então $\E{X} = 1$.

Falso, obtento o primeiro momento a partir da f.g.m. temos:
\begin{align*}
    \E{X} 
    &= M_X'(t) \Big|_0 \\
    &= e^{2.5 e^t - 2.5} 2.5 e^t \Big|_0 \\
    &= e^{2.5 - 2.5} 2.5 \\
    &= 2.5 \neq 1
\end{align*}

c) Sejam $X_1, X_2, X_3$ variáveis aleatórias independentes tais que $X_1 \sim \text{Bin}(5, 1/3), X_2 \sim \text{Bin}(10, 1/3)$ e $X_3 \sim \text{Bin}(15, 1/3)$, então $X_1 + X_2 + X_3 \sim \text{Bin}(25, 1/3)$.

Falso, usando o fato de que $M_{X + Y}(t) = M_X(t)M_Y(t)$ vista na questão 6. e que a f.g.m. de uma $\text{Bin}(n,p)$ é dada por $(1-p+pe^t)^n$, podemos ver que soma de duas V.A.s de distribuição binomial de probabilidades iguais é também binomial com a soma dos tamanhos $n$ de cada um.
\begin{align*}
    M_{X + Y}(t) 
    = \ &M_X(t)M_Y(t) \\
    = \ &(1-p+pe^t)^{n_1} (1-p+pe^t)^{n_2} \\
    = \ &(1-p+pe^t)^{n_1 + n_2} \\
    \implies &X+Y \sim \text{Bin}(n_1+n_2,p)
\end{align*}

Porém, 5 + 10 + 15 = 30, então $X_1 + X_2 + X_3$ teria que ter distribuição $\text{Bin}(30, 1/3)$.

